# Phase 7: 고도화 설계 및 한계점 극복 방안

## 1. 개요

본 문서는 `Phase 7`의 초기 설계안에 대해 제기될 수 있는 잠재적 한계점들을 비판적으로 검토하고, 이에 대한 구체적이고 실행 가능한 해결책을 제시하여 시스템의 완성도를 높이는 것을 목표로 한다. 이는 AI 기반 QA 시스템이 단순한 자동화 도구를 넘어, 인간 개발자의 창의성과 통찰력을 보조하는 진정한 '조력자'로 기능하기 위한 심화 설계안이다.

---

## 2. 'AI 블랙박스'의 함정 및 해결책

AI가 보상 함수의 허점을 파고들거나, 통계적 평균의 함정에 빠지는 문제를 방지하기 위한 방안이다.

### 해결책 1-A: '금지된 지식(Taboo Knowledge)'과 '호기심(Curiosity)'의 도입
- **방법:**
  1.  **부정적 보상(Negative Reward) 추가:** 현재의 통합 보상 함수에 페널티 항목을 추가한다. AI가 특정 행동을 비정상적으로 반복(어뷰징)하거나, 특정 영역에만 머무르는(꼼수) 등의 패턴을 보일 경우 감점을 부여한다.
  2.  **호기심 기반 탐색(Curiosity-Driven Exploration) 적용:** AI가 단순히 높은 보상을 받는 행동만 반복하지 않도록, 이전에 시도하지 않았던 새로운 전략이나 콤보를 탐색했을 때 추가적인 보상을 제공한다.
- **기대 효과:** AI가 보상 함수를 '해킹'하는 것이 아니라, 인간 플레이어처럼 다양하고 건전한 범위 내에서 최적의 전략을 탐색하도록 유도한다.

### 해결책 1-B: 'AI 페르소나'의 분리 및 교차 검증
- **방법:** 단일 AI가 아닌, 다양한 숙련도와 플레이 스타일을 가진 'AI 페르소나' 그룹을 운영한다.
  - **'초보자 AI':** 반응 속도가 느리고, 간단한 기술 위주로 플레이한다.
  - **'프로게이머 AI':** 프레임 단위의 완벽한 입력을 하며, 최대 효율을 추구한다.
  - **'압박형 AI':** 방어보다는 공격에 치중하며, 끊임없이 상대를 몰아붙인다.
- **기대 효과:** "프로게이머 기준으로는 밸런스가 맞지만, 초보자에게는 A 캐릭터가 너무 어렵다" 와 같이, 특정 플레이어 그룹이 겪을 수 있는 실질적인 밸런스 문제를 다각적으로 분석할 수 있다. '평균 승률 50%'라는 함정에서 벗어날 수 있다.

---

## 3. '손맛' 정량화의 한계 및 해결책

'손맛'을 단순한 물리적 피드백의 합으로 보는 시각에서 벗어나, 그 이면의 맥락과 리듬을 포착하는 방안이다.

### 해결책 2-A: '순간'이 아닌 '리듬(Rhythm)'의 측정
- **방법:** `Metric Extractor`의 분석 범위를 확장하여, 타격 성공의 '순간'뿐만 아니라 액션과 액션 사이의 '관계'와 '흐름'을 측정한다.
  - **신규 지표 예시:** `기대감 지수`(공격이 명중하기까지 걸린 시간), `콤보 연계성`(콤보를 이어갈 수 있는 시간적 여유), `카운터플레이 쾌감`(상대의 공격을 아슬아슬하게 피하고 반격했을 때의 시간차).
- **기대 효과:** '손맛'을 개별 점수의 합이 아닌, '기-승-전-결'의 서사를 가진 시퀀스로 평가할 수 있게 된다. 이를 통해 "묵직한 한 방의 손맛"과 "짜릿한 역전의 손맛"을 구분하여 분석하는 등, 훨씬 깊이 있는 평가가 가능해진다.

### 해결책 2-B: RLHF 방식 고도화 (A/B 테스트 및 평가자 다양성 확보)
- **방법:**
  1.  **'선호도 투표' 방식 도입:** 인간 평가자에게 점수를 매기게 하는 대신, 두 개의 다른 플레이 영상 클립(A/B)을 보여주고 "어느 쪽이 더 타격감이 좋았나요?"라고 묻는 쌍대 비교(Pairwise Comparison) 방식으로 데이터를 수집한다.
  2.  **평가자 그룹 다각화:** 평가자 그룹을 하드코어 유저, 일반 유저, 비숙련자 등으로 다양하게 구성하여 각 그룹의 선호도 데이터를 별도로 수집하고 분석한다.
- **기대 효과:** 소수 평가자의 주관적 편향을 최소화하고, "코어 유저층은 A를 선호했지만, 대중은 B의 직관성을 더 높게 평가했다" 와 같이 타겟 유저층에 따른 미묘한 선호도 차이까지 분석하여 기획에 반영할 수 있다.

---

## 4. '시뮬레이션의 배신' 및 해결책

AI의 초인적인 플레이가 아닌, 인간의 불완전함과 실제 온라인 환경의 변수를 시뮬레이션에 반영하는 방안이다.

### 해결책 3-A: '인간적 실수(Human Error)' 레이어 도입
- **방법:** AI 에이전트의 완벽한 행동 명령과 게임 엔진 사이에 가상의 '실수 주입 레이어'를 추가한다. 이 레이어는 AI의 입력을 일정 확률로 지연시키거나(반응 속도), 다른 입력으로 바꾸거나(오타), 누락시키는(입력 씹힘) 역할을 한다.
- **기대 효과:** "이 콤보는 이론상 가능하지만, 1프레임의 오차도 허용하지 않아 실전 성공률은 1% 미만이다" 와 같이, 이론적 성능과 실전적 유효성의 괴리를 분석하여 AI에게만 유효한 '죽은 데이터'를 걸러낼 수 있다.

### 해결책 3-B: '외생 변수' 및 '심리적 교란' 시뮬레이션
- **방법:**
  1.  **가변적 네트워크 환경 시뮬레이션:** `Simulation Arena`에 가변적인 네트워크 지연(Latency) 및 패킷 손실(Packet Loss)을 시뮬레이션하는 기능을 추가한다.
  2.  **'트롤(Troll) AI' 투입:** '승리'가 아닌 '상대방의 플레이 패턴을 방해하는 것'을 목표로 하는 특수 AI를 투입한다. 이 AI는 의도적인 지연 플레이, 특정 약한 기술 반복 등 상대방의 심리를 교란하는 행동을 하도록 학습된다.
- **기대 효과:** 안정적인 환경에서는 발견할 수 없는 온라인 플레이의 문제점(예: 특정 기술의 랙 취약성, 특정 플레이 스타일에 대한 스트레스 유발)을 사전에 테스트하고 개선할 수 있다.

---

## 5. 'AI 리포트의 객관성'의 신기루 및 해결책

AI 리포트를 '정답'이 아닌, 인간의 판단과 창의성을 돕는 '영감을 주는 질문'으로 전환하는 방안이다.

### 해결책 4-A: 리포트 언어를 '확정'에서 '가설'로 전환
- **방법:** `Report Generator`가 생성하는 텍스트의 톤 앤 매너를 '단정적' 표현에서 '가설 제시형'으로 변경한다.
  - **As-Is:** "문제점: A 캐릭터는 OP이므로 너프 필요."
  - **To-Be:** "발견: A 캐릭터의 승률이 72%로 관측됨. 이것이 기획 의도에 부합하는지, 혹은 특정 조건에서만 발생하는 현상인지 검토가 필요함."
- **기대 효과:** AI 리포트가 기획자의 판단을 대체하는 '감독관'이 아니라, 새로운 관점과 질문을 던져주는 '조력자' 역할을 하게 된다. 데이터의 해석과 최종 결정의 주체는 인간임을 명확히 한다.

### 해결책 4-B: '설명 가능한 AI(XAI)' 리포트 도입
- **방법:** 리포트에 최종 분석 결과(숫자, 그래프)만 제시하는 것이 아니라, **AI가 왜 그런 결론을 내렸는지에 대한 근거 데이터(영상 클립, 상세 로그, 히트맵 등)를 반드시 함께 제공**한다.
  - 예: '손맛 점수가 낮은 스킬' 항목에는 해당 스킬이 사용되는 실제 플레이 영상 클립들을 여러 개 첨부하여, 개발자가 직접 보고 맥락을 파악할 수 있게 한다.
- **기대 효과:** AI의 분석 과정을 투명하게 공개하여 '블랙박스' 문제를 해소하고, 개발자가 결과에 맹목적으로 의존하는 것을 방지한다. 데이터의 맥락을 비판적으로 수용하고 집단 지성을 통해 더 나은 결정을 내리도록 돕는다.
