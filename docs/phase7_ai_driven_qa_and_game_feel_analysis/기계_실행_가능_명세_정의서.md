# Phase 7: 기계 실행 가능 명세 정의서 (v2.0)

## 1. 개요

본 문서는 AI 기반 자동 QA 시스템의 설정, 데이터 프로토콜, API 등을 기계가 직접 읽고 검증할 수 있는(Machine-Readable) 형태로 명세한다. 이를 통해 시스템의 설정 오류를 사전에 방지하고, 데이터의 정합성을 강제하며, 자동화된 테스트를 용이하게 한다.

## 2. 실행 환경 및 설정 명세 (YAML & Pydantic) (v2.0)

시스템의 모든 설정은 `config.yaml` 파일로 관리하며, `Pydantic` 모델을 사용하여 해당 설정 파일의 유효성을 검증한다.

### 2.1. `config.yaml` (v2.0 예시)

```yaml
# config.yaml

version: 2.0

# 시뮬레이션 환경 설정
simulation:
  game_executable_path: "/path/to/game.exe"
  total_matches: 1000
  ipc_protocol: "webrtc"
  port: 50051
  # (추가) 인간적 실수 레이어 설정
  human_error_layer:
    enabled: true
    reaction_time_mean: 0.1 # 초 단위
    reaction_time_std: 0.02
    mistake_probability: 0.05 # 5% 확률로 오타
    drop_probability: 0.01 # 1% 확률로 입력 누락

# RL 에이전트 설정
agent:
  # (추가) 페르소나 설정
  personas:
    - id: "pro_gamer"
      model_path: "/models/pro_gamer.zip"
      human_error_layer: null # 전용 설정이 없으면 전역 설정 사용
    - id: "beginner"
      model_path: "/models/beginner.zip"
      human_error_layer:
        mistake_probability: 0.15
        drop_probability: 0.05
  # 기본 알고리즘 설정
  algorithm: "PPO"
  policy: "MlpPolicy"
  learning_rate: 0.0003
  # (추가) 호기심 모듈 설정
  curiosity:
    enabled: true
    strength: 0.01
  # 보상 함수 가중치
  reward_weights:
    stability: 0.1
    balance: 0.4
    responsiveness: 0.2
    immersion: 0.3

# 리포팅 설정
reporting:
  generate_video: true
  retention_days: 90
```

### 2.2. `settings.py` (Pydantic 검증 모델 v2.0)

```python
# settings.py
from pydantic import BaseModel, Field, FilePath
from typing import Literal, List, Optional

# --- v2.0 추가 --- #
class HumanErrorSettings(BaseModel):
    enabled: bool = True
    reaction_time_mean: float = Field(0.1, ge=0)
    reaction_time_std: float = Field(0.02, ge=0)
    mistake_probability: float = Field(0.05, ge=0, le=1)
    drop_probability: float = Field(0.01, ge=0, le=1)

class Persona(BaseModel):
    id: str
    model_path: FilePath
    human_error_layer: Optional[HumanErrorSettings] = None

class CuriositySettings(BaseModel):
    enabled: bool = False
    strength: float = Field(0.01, ge=0)
# --- v2.0 추가 끝 --- #

class RewardWeights(BaseModel):
    stability: float = Field(..., ge=0, le=1)
    balance: float = Field(..., ge=0, le=1)
    responsiveness: float = Field(..., ge=0, le=1)
    immersion: float = Field(..., ge=0, le=1)

class AgentSettings(BaseModel):
    personas: List[Persona]
    algorithm: Literal["PPO", "A2C", "DQN"]
    policy: str
    learning_rate: float = Field(..., gt=0)
    curiosity: CuriositySettings = Field(default_factory=CuriositySettings)
    reward_weights: RewardWeights

class SimulationSettings(BaseModel):
    game_executable_path: FilePath
    total_matches: int = Field(..., gt=0)
    ipc_protocol: Literal["webrtc"]
    port: int = Field(..., gt=1023, lt=65536)
    human_error_layer: HumanErrorSettings = Field(default_factory=HumanErrorSettings)

class ReportingSettings(BaseModel):
    generate_video: bool
    retention_days: int = Field(..., ge=1)

class AppSettings(BaseModel):
    version: float
    simulation: SimulationSettings
    agent: AgentSettings
    reporting: ReportingSettings
```

## 3. 데이터 프로토콜 명세 (JSON Schema) (v2.0)

`Log Collector`가 생성하는 이벤트 로그(`events.jsonl`)의 각 라인은 아래의 `JSON Schema`에 의해 검증될 수 있다.

### 3.1. `event_schema.json` (v2.0)
- **(변경)** `event_type`의 `enum`에 `HUMAN_ERROR_INJECTED_EVENT`, `RHYTHM_METRIC_EVENT`, `XAI_EVIDENCE_LINK_EVENT` 추가.
- **(변경)** `if/then` 구문을 사용하여 각 신규 이벤트 타입에 대한 `data` 객체의 세부 스키마를 별도로 정의.

## 4. API 명세 (OpenAPI - 선택 사항)

(v1.0과 동일. 향후 API 확장 시 이 부분도 구체화)
