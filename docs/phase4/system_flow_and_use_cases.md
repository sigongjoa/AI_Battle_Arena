# 시스템 흐름 및 유즈케이스 명세서

## 1. 개요

본 문서는 'RL-over-WebRTC' 시스템의 기능적 요구사항을 설명하고, 주요 액터(Actor)의 관점에서 시스템의 동작 흐름을 유즈케이스(Use Case) 형태로 정의한다. 이는 시스템이 '무엇을' 하는지에 초점을 맞춘다.

## 2. 액터 (Actors)

-   **개발자 (Developer)**: 시스템의 주 사용자로, AI 학습을 시작하고, 모니터링하며, 결과를 확인하는 역할을 수행한다.
-   **시스템 (System)**: 본 문서에서 설명하는 전체 소프트웨어(백엔드, 프론트엔드, 시그널링 서버 포함)를 지칭한다.

## 3. 유즈케이스 (Use Cases)

### UC-01: AI 모델 성공적인 학습

-   **액터**: 개발자
-   **목표**: AI 에이전트가 게임을 플레이하며 학습하고, 그 결과로 학습된 모델 파일과 로그가 생성된다.
-   **사전 조건**:
    -   시그널링 서버가 정상적으로 실행 중이다.
    -   백엔드 Python 환경에 필요한 라이브러리가 모두 설치되어 있다.
    -   프론트엔드 개발 서버가 실행 중이거나, 빌드된 정적 파일이 웹서버를 통해 제공되고 있다.

-   **주요 흐름 (Main Flow)**:
    1.  **개발자**는 백엔드 학습 스크립트를 실행한다. (예: `python train_rl_agent.py`)
    2.  **시스템(백엔드)**은 자신의 Peer ID를 생성하여 시그널링 서버에 등록하고, 프론트엔드 클라이언트의 연결을 대기 상태에 들어간다. 터미널에는 "Waiting for frontend connection on Peer ID: backend-agent-xxx"와 같은 메시지가 출력된다.
    3.  **개발자**는 브라우저를 열고, 백엔드가 알려준 Peer ID를 포함한 특정 URL로 접속한다. (예: `http://localhost:5173/?mode=rl_training&backend_peer_id=backend-agent-xxx`)
    4.  **시스템(프론트엔드)**은 URL을 파싱하여 학습 모드임을 인지하고, 백엔드 Peer ID로 WebRTC 연결을 시도한다.
    5.  **시스템(백엔드/프론트엔드)**은 시그널링 서버를 통해 P2P 정보를 교환하고, 데이터 채널을 성공적으로 수립한다.
    6.  **시스템(프론트엔드)**은 데이터 채널이 열리면 백엔드로 `connection_ready` 메시지를 전송한다.
    7.  **시스템(백엔드)**은 `connection_ready` 메시지를 수신하고 대기 상태를 해제한 후, `reset` 명령을 프론트엔드로 보내며 본격적인 학습 루프를 시작한다.
    8.  학습이 지정된 타임스텝만큼 진행된다.
    9.  **시스템(백엔드)**은 학습 완료 후, 최종 모델 파일(예: `ppo_fighting_env.zip`)을 `models/` 디렉토리에 저장하고, 학습 로그를 `logs/` 디렉토리에 기록한 뒤 정상적으로 프로세스를 종료한다.

### UC-02: WebRTC 연결 실패

-   **액터**: 개발자
-   **목표**: 잘못된 정보로 인해 WebRTC 연결이 실패했을 때, 시스템이 오류를 명확히 인지시키고 비정상 종료되지 않는다.
-   **사전 조건**: UC-01과 동일.

-   **주요 흐름 (Alternative Flow)**:
    1.  UC-01의 1-2단계와 동일하게 진행된다.
    2.  **개발자**가 브라우저 URL에 **잘못된** 백엔드 Peer ID를 입력한다. (예: `...&backend_peer_id=invalid-id`)
    3.  **시스템(프론트엔드)**은 존재하지 않는 Peer ID로 연결을 시도하고, 시그널링 서버로부터 "Peer not found" 응답을 받거나 타임아웃이 발생한다.
    4.  **시스템(프론트엔드)**은 화면에 "백엔드 연결 실패: Peer ID를 찾을 수 없습니다."와 같은 오류 메시지를 표시한다.
    5.  **시스템(백엔드)**은 프론트엔드의 연결이 없으므로 `FightingEnv` 초기화 과정에서 설정된 타임아웃(예: 60초)이 만료된다.
    6.  **시스템(백엔드)**은 `TimeoutError`를 발생시키고, "Frontend connection timed out." 로그를 남기며 정상적으로 프로세스를 종료한다.

### UC-03: 학습 중 연결 끊김

-   **액터**: 개발자
-   **목표**: 학습 도중 예기치 않게 연결이 끊겼을 때, 시스템이 현재까지의 학습 진행 상황을 최대한 보존하고 안전하게 종료된다.
-   **사전 조건**: UC-01의 학습 루프가 진행 중이다.

-   **주요 흐름 (Exception Flow)**:
    1.  학습 루프가 정상적으로 실행되던 중, **개발자**가 브라우저 탭을 닫거나 네트워크 연결을 해제한다.
    2.  **시스템(백엔드)**의 `FightingEnv.step()` 메서드가 프론트엔드로부터의 `step_result` 메시지를 기다리다가 타임아웃(10초)이 발생한다.
    3.  `FightingEnv`는 `TimeoutError` 예외를 발생시킨다.
    4.  **시스템(백엔드)**의 `train_rl_agent.py`는 이 예외를 감지하고, `model.save()`를 호출하여 현재까지 학습된 모델을 중간 저장(예: `ppo_fighting_env_interrupted.zip`)한다.
    5.  **시스템(백엔드)**은 "Connection lost during training. Saving current model..." 로그를 남기고 프로세스를 종료한다.

### UC-04: 학습 결과 확인

-   **액터**: 개발자
-   **목표**: 완료된 학습의 성과를 시각적으로 확인한다.
-   **사전 조건**: UC-01이 최소 1회 이상 성공적으로 완료되었다.

-   **주요 흐름 (Main Flow)**:
    1.  **개발자**는 터미널에서 `tensorboard --logdir ./logs` 명령을 실행한다.
    2.  **시스템(TensorBoard)**은 `logs/` 디렉토리의 로그 파일을 읽어 웹 서버를 실행하고, URL(예: `http://localhost:6006/`)을 출력한다.
    3.  **개발자**는 해당 URL을 브라우저에서 연다.
    4.  **시스템(TensorBoard)**은 평균 보상, 에피소드 길이, 승률 등의 학습 지표를 그래프로 시각화하여 보여준다.
