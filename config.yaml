rl_training:
  active_policy: PPO
  policies:
    PPO:
      algorithm: PPO
      hyperparameters:
        learning_rate: 0.0003
        n_steps: 2048
        batch_size: 64
        gamma: 0.99
        gae_lambda: 0.95
        clip_range: 0.2
        ent_coef: 0.01
        vf_coef: 0.5
        max_grad_norm: 0.5
        n_epochs: 10
    A2C:
      algorithm: A2C
      hyperparameters:
        learning_rate: 0.0007
        n_steps: 5
        gamma: 0.99
        gae_lambda: 1.0
        ent_coef: 0.01
        vf_coef: 0.5
        max_grad_norm: 0.5

training_config:
  total_timesteps: 1_000_000
  eval_freq: 10000
  n_eval_episodes: 5
  n_envs: 1 # Number of parallel environments
  # reward_threshold: 200 # Uncomment to enable StopTrainingOnRewardThreshold